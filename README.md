# Deep Learning notebooks

This repository contains three Python notebooks serving as guidelines for the implementation in TensorFlow - Keras of the following deep learning architectures:
- **Recurrent Neural Networks (RNN) for sentiment analysis** 
<a target="_blank" href="https://colab.research.google.com/github/silviapoletti/Deep_Learning_notebooks/blob/bb07ef04ec38c805b0c79cef6d594db4dba66e16/recurrent_neural_networks.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

  - Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks
  - Bidirectional LSTM network
  - Dropout Layer and other tecniques to reduce overfitting
- **Autoencoders (AE)** 
<a target="_blank" href="https://colab.research.google.com/github/silviapoletti/Deep_Learning_notebooks/blob/bb07ef04ec38c805b0c79cef6d594db4dba66e16/autoencoders.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

  - The relationship between shallow linear AE and the Singular Value Decomposition (SVD)
  - Shallow/deep non-linear AE for hand-written digit recognition
  - Denoising AE
  - AE for sequences (sentiment analysis task)
- **Variational Autoencoders (VAE) on hand-written digits** 
<a target="_blank" href="https://colab.research.google.com/github/silviapoletti/Deep_Learning_notebooks/blob/bb07ef04ec38c805b0c79cef6d594db4dba66e16/variational_autoencoders.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

  - The reparametrization trick
  - Data generation using the decoder
  - Visualization of the VAE's latent space

The notebooks also contain very useful insights about the implementation and the mentioned architectures.
